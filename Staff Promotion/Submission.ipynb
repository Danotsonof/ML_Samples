{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promotion Prediction\n",
    "### Data Science Nigeria Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.set_index('EmployeeNo',inplace=True)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.set_index('EmployeeNo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data[data.columns[:9]].drop(columns=['Year_of_birth','Year_of_recruitment'])\n",
    "data2=data[data.columns[9:]].drop(columns=['Training_score_average','State_Of_Origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "plt.suptitle('Pie Chart Distributions', fontsize=20)\n",
    "for i in range(1, data1.shape[1]+1):\n",
    "    plt.subplot(3,3,i)\n",
    "    f = plt.gca()\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "    f.set_title(data1.columns.values[i-1])\n",
    "    \n",
    "    values = data1.iloc[:, i - 1].value_counts(normalize = True).values\n",
    "    index = data1.iloc[:, i - 1].value_counts(normalize = True).index\n",
    "    plt.pie(values, labels = index, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "plt.suptitle('Pie Chart Distributions', fontsize=20)\n",
    "for i in range(1, data2.shape[1]+1):\n",
    "    plt.subplot(3,3,i)\n",
    "    f = plt.gca()\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "    f.set_title(data2.columns.values[i-1])\n",
    "    \n",
    "    values = data2.iloc[:, i - 1].value_counts(normalize = True).values\n",
    "    index = data2.iloc[:, i - 1].value_counts(normalize = True).index\n",
    "    plt.pie(values, labels = index, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Previous_Award')['Promoted_or_Not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Targets_met')['Promoted_or_Not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Past_Disciplinary_Action')['Promoted_or_Not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Foreign_schooled')['Promoted_or_Not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Previous_IntraDepartmental_Movement')['Promoted_or_Not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Promoted_or_Not']\n",
    "data = data.drop(columns='Promoted_or_Not')\n",
    "merged = pd.concat([data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['Past_Disciplinary_Action'] = merged.Past_Disciplinary_Action.map(\n",
    "    {'No' : 1,'Yes' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['Previous_IntraDepartmental_Movement'] = merged.Previous_IntraDepartmental_Movement.map(\n",
    "    {'No' : 1,'Yes' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['Foreign_schooled'] = merged.Foreign_schooled.map(\n",
    "    {'No' : 0,'Yes' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['No_of_previous_employers'] = merged.No_of_previous_employers.map(\n",
    "    {'0' : 6,'1' : 5,'2' : 4,'3':3,'4':2,'5':1,'More than 5':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['Qualification'].fillna('First Degree or HND', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_Yr = 2019\n",
    "merged['Years_in_Service'] = merged['Year_of_recruitment'].apply(lambda x :cur_Yr - x)\n",
    "merged['Age'] = merged['Year_of_birth'].apply(lambda x :cur_Yr - x)\n",
    "merged = merged.drop(['Year_of_recruitment','Year_of_birth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One hot encoding\n",
    "merged = pd.concat([merged[['Trainings_Attended','Last_performance_score','Targets_met',\n",
    "                                'Previous_Award','Training_score_average', 'Previous_IntraDepartmental_Movement',\n",
    "                                'No_of_previous_employers','Years_in_Service','Age',\n",
    "                                'Past_Disciplinary_Action', 'Foreign_schooled']],\n",
    "               pd.get_dummies(merged['Division'],drop_first = True),\n",
    "                      pd.get_dummies(merged['Qualification'],drop_first = True),\n",
    "                      pd.get_dummies(merged['Gender'],drop_first = True),\n",
    "                      pd.get_dummies(merged['Channel_of_Recruitment'],drop_first = True),\n",
    "                      pd.get_dummies(merged['State_Of_Origin'],drop_first = True),\n",
    "                      pd.get_dummies(merged['Marital_Status'],drop_first = True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "merged[0:38312].\\\n",
    "corrwith(target).plot.bar(figsize=(20,10), \\\n",
    "                              title = 'Correletion with Response variable',\\\n",
    "                             fontsize = 15, rot = 45, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "\n",
    "# X_train2 = pd.DataFrame(sc_X.fit_transform(merged))\n",
    "# X_train2.columns = merged.columns.values\n",
    "# X_train2.index = merged.index.values\n",
    "# merged = X_train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = merged[38312:]\n",
    "X = merged[0:38312]\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Hypertuning\n",
    "### Param test 1\n",
    "\n",
    "param_test1 = {\n",
    "  'min_child_weight':range(1,6,2),\n",
    "  'max_depth': range(3,10,2)\n",
    "  #'n_estimators':[150,200,300,400],\n",
    "  #'scale_pos_weight':[1,2,3,4],\n",
    "  #'colsample_bytree':[0.7,0.8], \n",
    "  #'subsample':[0.7,0.8],\n",
    "  #'gamma':[0,0.2,0.4]    \n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=5, \n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "                                                  nthread=4, scale_pos_weight=3,seed=27), \n",
    "                        param_grid = param_test1, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch1.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch1.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "### Param test 2\n",
    "param_test2 = {\n",
    "  'min_child_weight':[1],\n",
    "  'max_depth': [5,6]\n",
    "  #'n_estimators':[150,200,300,400],\n",
    "  #'scale_pos_weight':[1,2,3,4],\n",
    "  #'colsample_bytree':[0.7,0.8], \n",
    "  #'subsample':[0.7,0.8],\n",
    "  #'gamma':[0,0.2,0.4]    \n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=5, \n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "                                                  nthread=4, scale_pos_weight=3,seed=27), \n",
    "                        param_grid = param_test2, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch2.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch2.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Param test 2\n",
    "\n",
    "param_test2 = {\n",
    "#   'min_child_weight':[1,2],\n",
    "#   'max_depth': [4,5,6]\n",
    "  'n_estimators':[150,200,250,500],\n",
    "  'scale_pos_weight':[1,2,3,4],\n",
    "  #'colsample_bytree':[0.7,0.8], \n",
    "  #'subsample':[0.7,0.8],\n",
    "  #'gamma':[0,0.2,0.4]    \n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=4, \n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "                                                  nthread=4, scale_pos_weight=3,seed=27), \n",
    "                        param_grid = param_test2, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch2.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch2.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Param test 3\n",
    "\n",
    "param_test3 = {\n",
    "#   'min_child_weight':[1,2],\n",
    "#   'max_depth': [4,5,6]\n",
    "#   'n_estimators':[150,200,300,400],\n",
    "#   'scale_pos_weight':[1,2,3,4],\n",
    "  'colsample_bytree':[0.7,0.8], \n",
    "  'subsample':[0.7, 0.8],\n",
    "  'gamma':[0,0.2,0.4]    \n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=4, \n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "                                                  nthread=4, scale_pos_weight=3,seed=27), \n",
    "                        param_grid = param_test3, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch3.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch3.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Param test 4\n",
    "\n",
    "param_test4 = {\n",
    "#   'min_child_weight':[1,2],\n",
    "#   'max_depth': [4,5,6]\n",
    "#   'n_estimators':[150,200,300,400],\n",
    "#   'scale_pos_weight':[1,2,3,4],\n",
    "  'colsample_bytree':[0.7,0.8], \n",
    "  'subsample':[0.7, 0.8],\n",
    "#   'gamma':[0.4]    \n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "n_estimators=150, max_depth=4, min_child_weight=1, gamma=0.4, \n",
    "subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "nthread=4, scale_pos_weight=3,seed=27), \n",
    "param_grid = param_test4, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch4.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch4.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Param test 5\n",
    "\n",
    "\n",
    "param_test5 = {\n",
    "'learning_rate':[0.1,0.01,0.001]   \n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "n_estimators=150, max_depth=4, min_child_weight=1, gamma=0.4, \n",
    "subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "nthread=4, scale_pos_weight=3,seed=27), \n",
    "param_grid = param_test5, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch5.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch5.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Param test 6\n",
    "\n",
    "param_test6 = {\n",
    "'reg_alpha':[0,0.1,1],\n",
    "'reg_lambda':[0,0.1,1],   \n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "n_estimators=150, max_depth=4, min_child_weight=1, gamma=0.4, \n",
    "subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "nthread=4, scale_pos_weight=3,seed=27), \n",
    "param_grid = param_test6, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train, y_train)\n",
    "print(\"gsearch.best_params_\",gsearch6.best_params_)\n",
    "print(\"gsearch.best_score_\",gsearch6.best_score_)\n",
    "print(\"gsearch.best_estimator_\",gsearch6.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate=0.1, \n",
    "n_estimators=250, max_depth=4, min_child_weight=1, gamma=0.4, \n",
    "subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "nthread=4, scale_pos_weight=3,seed=27)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"accuracy_score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test, y_pred)) # tp / (tp + fp)\n",
    "print(\"recall_score:\", recall_score(y_test, y_pred)) # tp / (tp + fn)\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred))\n",
    "print(\"confusion_matrix :\\n\", pd.DataFrame(cm))\n",
    "print(\"roc_auc test set:\", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
    "print(\"roc_auc training set:\", roc_auc_score(y_train, model.predict_proba(X_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate=0.1, \n",
    "n_estimators=250, max_depth=4, min_child_weight=1, gamma=0.4, \n",
    "subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', \n",
    "nthread=4, scale_pos_weight=3,seed=27)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"accuracy_score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test, y_pred)) # tp / (tp + fp)\n",
    "print(\"recall_score:\", recall_score(y_test, y_pred)) # tp / (tp + fn)\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred))\n",
    "print(\"confusion_matrix :\\n\", pd.DataFrame(cm))\n",
    "print(\"roc_auc test set:\", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
    "print(\"roc_auc training set:\", roc_auc_score(y_train, model.predict_proba(X_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid = merged[38312:]\n",
    "X_val = X_valid.copy()\n",
    "y_valid = model.predict(X_valid)\n",
    "submission = X_val\n",
    "submission['Promoted_or_Not'] = y_valid\n",
    "print(submission['Promoted_or_Not'].value_counts())\n",
    "\n",
    "# Exporting results a csv file\n",
    "submission = submission[['Promoted_or_Not']]\n",
    "submission.reset_index(inplace=True)\n",
    "submission.to_csv(\"Prediction8.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
